---
title: Metriche di ML.NET
description: Informazioni sulle metriche usate per valutare le prestazioni di un modello ML.NET
ms.date: 12/17/2019
author: natke
ms.author: nakersha
ms.openlocfilehash: b154c88281b65730c107a52034dfa40a45d4e367
ms.sourcegitcommit: 30a558d23e3ac5a52071121a52c305c85fe15726
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 12/25/2019
ms.locfileid: "75347763"
---
# <a name="evaluate-your-mlnet-model-with-metrics"></a><span data-ttu-id="abeba-103">Valutare il modello ML.NET con le metriche</span><span class="sxs-lookup"><span data-stu-id="abeba-103">Evaluate your ML.NET model with metrics</span></span>

<span data-ttu-id="abeba-104">Informazioni sulle metriche usate per valutare un modello ML.NET.</span><span class="sxs-lookup"><span data-stu-id="abeba-104">Understand the metrics used to evaluate an ML.NET model.</span></span>

<span data-ttu-id="abeba-105">Le metriche di valutazione sono specifiche del tipo di attività di Machine Learning eseguita da un modello.</span><span class="sxs-lookup"><span data-stu-id="abeba-105">Evaluation metrics are specific to the type of machine learning task that a model performs.</span></span>

<span data-ttu-id="abeba-106">Per l'attività di classificazione, ad esempio, il modello viene valutato misurando il modo in cui una categoria stimata corrisponde alla categoria effettiva.</span><span class="sxs-lookup"><span data-stu-id="abeba-106">For example, for the classification task, the model is evaluated by measuring how well a predicted category matches the actual category.</span></span> <span data-ttu-id="abeba-107">Per il clustering, la valutazione è basata sul modo in cui gli elementi del cluster si chiudono tra loro e sulla quantità di separazione tra i cluster.</span><span class="sxs-lookup"><span data-stu-id="abeba-107">And for clustering, evaluation is based on how close clustered items are to each other, and how much separation there is between the clusters.</span></span>

## <a name="evaluation-metrics-for-binary-classification"></a><span data-ttu-id="abeba-108">Metriche di valutazione per la classificazione binaria</span><span class="sxs-lookup"><span data-stu-id="abeba-108">Evaluation metrics for Binary Classification</span></span>

| <span data-ttu-id="abeba-109">Metrica</span><span class="sxs-lookup"><span data-stu-id="abeba-109">Metrics</span></span>   |      <span data-ttu-id="abeba-110">Descrizione</span><span class="sxs-lookup"><span data-stu-id="abeba-110">Description</span></span>      |  <span data-ttu-id="abeba-111">Cercare</span><span class="sxs-lookup"><span data-stu-id="abeba-111">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="abeba-112">**Accuracy**</span><span class="sxs-lookup"><span data-stu-id="abeba-112">**Accuracy**</span></span> |  <span data-ttu-id="abeba-113">[Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) o accuratezza corrisponde alla percentuale di stime corrette con un set di dati di test.</span><span class="sxs-lookup"><span data-stu-id="abeba-113">[Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) is the proportion of correct predictions with a test data set.</span></span> <span data-ttu-id="abeba-114">Equivale al rapporto tra il numero di stime corrette e il numero totale di campioni di input.</span><span class="sxs-lookup"><span data-stu-id="abeba-114">It is the ratio of number of correct predictions to the total number of input samples.</span></span> <span data-ttu-id="abeba-115">Funziona bene se è presente un numero simile di esempi appartenenti a ogni classe.</span><span class="sxs-lookup"><span data-stu-id="abeba-115">It works well if there are similar number of samples belonging to each class.</span></span>| <span data-ttu-id="abeba-116">**Quanto più vicino a 1,00, tanto meglio**.</span><span class="sxs-lookup"><span data-stu-id="abeba-116">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="abeba-117">Ma se il risultato è esattamente 1,00, significa che si è verificato un problema, in genere di tipo dispersione di dati (etichetta/destinazione), sovradattamento oppure uso di dati di training per il test.</span><span class="sxs-lookup"><span data-stu-id="abeba-117">But exactly 1.00 indicates an issue (commonly: label/target leakage, over-fitting, or testing with training data).</span></span> <span data-ttu-id="abeba-118">Quando i dati di test non sono bilanciati (dove la maggior parte delle istanze appartiene a una delle classi), il set di dati è di dimensioni ridotte o l'approccio con i punteggi 0,00 o 1,00, l'accuratezza non acquisisce effettivamente l'efficacia di un classificatore ed è necessario controllare le metriche aggiuntive.</span><span class="sxs-lookup"><span data-stu-id="abeba-118">When the test data is unbalanced (where most of the instances belong to one of the classes), the dataset is small, or scores approach 0.00 or 1.00, then accuracy doesn’t really capture the effectiveness of a classifier and you need to check additional metrics.</span></span> |
| <span data-ttu-id="abeba-119">**AUC**</span><span class="sxs-lookup"><span data-stu-id="abeba-119">**AUC**</span></span> |    <span data-ttu-id="abeba-120">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) o *area sotto la curva* misura l'area sotto la curva creata spostando il vero tasso positivo rispetto al tasso di falsi positivi.</span><span class="sxs-lookup"><span data-stu-id="abeba-120">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) or *Area under the curve* measures the area under the curve created by sweeping the true positive rate vs. the false positive rate.</span></span>  |   <span data-ttu-id="abeba-121">**Quanto più vicino a 1,00, tanto meglio**.</span><span class="sxs-lookup"><span data-stu-id="abeba-121">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="abeba-122">Deve essere maggiore di 0,50 affinché un modello sia accettabile.</span><span class="sxs-lookup"><span data-stu-id="abeba-122">It should be greater than 0.50 for a model to be acceptable.</span></span> <span data-ttu-id="abeba-123">Un modello con AUC 0,50 o meno è inutile.</span><span class="sxs-lookup"><span data-stu-id="abeba-123">A model with AUC of 0.50 or less is worthless.</span></span> |
| <span data-ttu-id="abeba-124">**AUCPR**</span><span class="sxs-lookup"><span data-stu-id="abeba-124">**AUCPR**</span></span> | <span data-ttu-id="abeba-125">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) o *area sotto la curva di una curva di richiamo di precisione*: misura utile di esito positivo della stima quando le classi sono sbilanciate (set di impostazioni di set di impostazioni molto inclinati).</span><span class="sxs-lookup"><span data-stu-id="abeba-125">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) or *Area under the curve of a Precision-Recall curve*: Useful measure of success of prediction when the classes are imbalanced (highly skewed datasets).</span></span> |  <span data-ttu-id="abeba-126">**Quanto più vicino a 1,00, tanto meglio**.</span><span class="sxs-lookup"><span data-stu-id="abeba-126">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="abeba-127">I punteggi elevati vicini a 1,00 mostrano che il classificatore restituisce risultati accurati (alta precisione), oltre a restituire una maggioranza di risultati tutti positivi (alto recupero).</span><span class="sxs-lookup"><span data-stu-id="abeba-127">High scores close to 1.00 show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).</span></span> |
| <span data-ttu-id="abeba-128">**F1-score**</span><span class="sxs-lookup"><span data-stu-id="abeba-128">**F1-score**</span></span> | <span data-ttu-id="abeba-129">[F1 score](https://en.wikipedia.org/wiki/F1_score) anche detto *F-score bilanciato o F-measure*.</span><span class="sxs-lookup"><span data-stu-id="abeba-129">[F1 score](https://en.wikipedia.org/wiki/F1_score) also known as *balanced F-score or F-measure*.</span></span> <span data-ttu-id="abeba-130">Si tratta della media armonica di precisione e recupero.</span><span class="sxs-lookup"><span data-stu-id="abeba-130">It's the harmonic mean of the precision and recall.</span></span> <span data-ttu-id="abeba-131">La metrica F1 Score è utile se si vuole trovare un equilibrio tra precisione e recupero.</span><span class="sxs-lookup"><span data-stu-id="abeba-131">F1 Score is helpful when you want to seek a balance between Precision and Recall.</span></span>| <span data-ttu-id="abeba-132">**Quanto più vicino a 1,00, tanto meglio**.</span><span class="sxs-lookup"><span data-stu-id="abeba-132">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="abeba-133">F1-score raggiunge il valore ottimale con un punteggio 1,00 e il valore peggiore con 0,00.</span><span class="sxs-lookup"><span data-stu-id="abeba-133">An F1 score reaches its best value at 1.00 and worst score at 0.00.</span></span> <span data-ttu-id="abeba-134">Indica il grado di precisione del classificatore.</span><span class="sxs-lookup"><span data-stu-id="abeba-134">It tells you how precise your classifier is.</span></span> |

<span data-ttu-id="abeba-135">Per altre informazioni sulle metriche di classificazione binaria, vedere gli articoli seguenti:</span><span class="sxs-lookup"><span data-stu-id="abeba-135">For further details on binary classification metrics read the following articles:</span></span>

- [<span data-ttu-id="abeba-136">Accuratezza, precisione, richiamo o F1?</span><span class="sxs-lookup"><span data-stu-id="abeba-136">Accuracy, Precision, Recall, or F1?</span></span>](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)
- [<span data-ttu-id="abeba-137">Classe BinaryClassificationMetrics</span><span class="sxs-lookup"><span data-stu-id="abeba-137">Binary Classification Metrics class</span></span>](xref:Microsoft.ML.Data.BinaryClassificationMetrics)
- [<span data-ttu-id="abeba-138">The Relationship Between Precision-Recall and ROC Curves</span><span class="sxs-lookup"><span data-stu-id="abeba-138">The Relationship Between Precision-Recall and ROC Curves</span></span>](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf)

## <a name="evaluation-metrics-for-multi-class-classification"></a><span data-ttu-id="abeba-139">Metriche di valutazione per la classificazione multiclasse</span><span class="sxs-lookup"><span data-stu-id="abeba-139">Evaluation metrics for Multi-class Classification</span></span>

| <span data-ttu-id="abeba-140">Metrica</span><span class="sxs-lookup"><span data-stu-id="abeba-140">Metrics</span></span>   |      <span data-ttu-id="abeba-141">Descrizione</span><span class="sxs-lookup"><span data-stu-id="abeba-141">Description</span></span>      |  <span data-ttu-id="abeba-142">Cercare</span><span class="sxs-lookup"><span data-stu-id="abeba-142">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="abeba-143">**Micro-Accuracy**</span><span class="sxs-lookup"><span data-stu-id="abeba-143">**Micro-Accuracy**</span></span> |  <span data-ttu-id="abeba-144">L'[accuratezza micro-media](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) aggrega i contributi di tutte le classi per calcolare la metrica media.</span><span class="sxs-lookup"><span data-stu-id="abeba-144">[Micro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) aggregates the contributions of all classes to compute the average metric.</span></span> <span data-ttu-id="abeba-145">Corrisponde alla percentuale di istanze stimate correttamente.</span><span class="sxs-lookup"><span data-stu-id="abeba-145">It is the fraction of instances predicted correctly.</span></span> <span data-ttu-id="abeba-146">La micro-media non tiene conto dell'appartenenza a una classe.</span><span class="sxs-lookup"><span data-stu-id="abeba-146">The micro-average does not take class membership into account.</span></span> <span data-ttu-id="abeba-147">Essenzialmente, ogni coppia campione-classe contribuisce nello stesso modo alla metrica di accuratezza.</span><span class="sxs-lookup"><span data-stu-id="abeba-147">Basically, every sample-class pair contributes equally to the accuracy metric.</span></span> | <span data-ttu-id="abeba-148">**Quanto più vicino a 1,00, tanto meglio**.</span><span class="sxs-lookup"><span data-stu-id="abeba-148">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="abeba-149">In un'attività di classificazione multiclasse la micro-accuratezza è preferibile rispetto alla macro-accuratezza se si sospetta uno squilibrio di classi, ossia</span><span class="sxs-lookup"><span data-stu-id="abeba-149">In a multi-class classification task, micro-accuracy is preferable over macro-accuracy if you suspect there might be class imbalance (i.e</span></span> <span data-ttu-id="abeba-150">la presenza di molti più esempi di una classe rispetto ad altre.</span><span class="sxs-lookup"><span data-stu-id="abeba-150">you may have many more examples of one class than of other classes).</span></span>|
| <span data-ttu-id="abeba-151">**Macro-Accuracy**</span><span class="sxs-lookup"><span data-stu-id="abeba-151">**Macro-Accuracy**</span></span> | <span data-ttu-id="abeba-152">L'[accuratezza macro-media](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) corrisponde all'accuratezza media a livello di classe.</span><span class="sxs-lookup"><span data-stu-id="abeba-152">[Macro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) is the average accuracy at the class level.</span></span> <span data-ttu-id="abeba-153">Viene confrontata l'accuratezza per ogni classe e l'accuratezza macro-media è la media di queste accuratezze.</span><span class="sxs-lookup"><span data-stu-id="abeba-153">The accuracy for each class is computed and the macro-accuracy is the average of these accuracies.</span></span> <span data-ttu-id="abeba-154">Essenzialmente, ogni classe contribuisce nello stesso modo alla metrica di accuratezza.</span><span class="sxs-lookup"><span data-stu-id="abeba-154">Basically, every class contributes equally to the accuracy metric.</span></span> <span data-ttu-id="abeba-155">Alle classi di minoranza viene assegnato un peso uguale a quello delle classi più grandi.</span><span class="sxs-lookup"><span data-stu-id="abeba-155">Minority classes are given equal weight as the larger classes.</span></span> <span data-ttu-id="abeba-156">La metrica della macro-media assegna lo stesso peso a ogni classe, indipendentemente dal numero di istanze di tale classe contenute nel set di dati.</span><span class="sxs-lookup"><span data-stu-id="abeba-156">The macro-average metric gives the same weight to each class, no matter how many instances from that class the dataset contains.</span></span> |  <span data-ttu-id="abeba-157">**Quanto più vicino a 1,00, tanto meglio**.</span><span class="sxs-lookup"><span data-stu-id="abeba-157">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="abeba-158">Calcola la metrica in modo indipendente per ogni classe e quindi ne considera la media, di conseguenza tratta tutte le classi allo stesso modo</span><span class="sxs-lookup"><span data-stu-id="abeba-158">It computes the metric independently for each class and then takes the average (hence treating all classes equally)</span></span> |
| <span data-ttu-id="abeba-159">**Log-loss**</span><span class="sxs-lookup"><span data-stu-id="abeba-159">**Log-loss**</span></span>| <span data-ttu-id="abeba-160">La [perdita logaritmica](http://wiki.fast.ai/index.php/Log_Loss) misura le prestazioni di un modello di classificazione in cui l'input della stima è un valore di probabilità compreso tra 0,00 e 1,00.</span><span class="sxs-lookup"><span data-stu-id="abeba-160">[Logarithmic loss](http://wiki.fast.ai/index.php/Log_Loss) measures the performance of a classification model where the prediction input is a probability value between 0.00 and 1.00.</span></span> <span data-ttu-id="abeba-161">Questa metrica aumenta quando la probabilità stimata devia dall'etichetta effettiva.</span><span class="sxs-lookup"><span data-stu-id="abeba-161">Log-loss increases as the predicted probability diverges from the actual label.</span></span> | <span data-ttu-id="abeba-162">**Quanto più vicino a 0,00, tanto meglio**.</span><span class="sxs-lookup"><span data-stu-id="abeba-162">**The closer to 0.00, the better**.</span></span> <span data-ttu-id="abeba-163">In un modello perfetto, log-loss sarebbe uguale a 0,00.</span><span class="sxs-lookup"><span data-stu-id="abeba-163">A perfect model would have a log-loss of 0.00.</span></span> <span data-ttu-id="abeba-164">L'obiettivo dei modelli di Machine Learning è ridurre al minimo questo valore.</span><span class="sxs-lookup"><span data-stu-id="abeba-164">The goal of our machine learning models is to minimize this value.</span></span>|
| <span data-ttu-id="abeba-165">**Log-Loss Reduction**</span><span class="sxs-lookup"><span data-stu-id="abeba-165">**Log-Loss Reduction**</span></span> | <span data-ttu-id="abeba-166">La [riduzione della perdita logaritmica](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) può essere interpretata come un vantaggio del classificatore rispetto alla stima casuale.</span><span class="sxs-lookup"><span data-stu-id="abeba-166">[Logarithmic loss reduction](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) can be interpreted as the advantage of the classifier over a random prediction.</span></span>| <span data-ttu-id="abeba-167">**Il valore è compreso nell'intervallo da -inf a 1,00, dove 1,00 corrisponde a stime perfette e 0,00 indica stime medie**.</span><span class="sxs-lookup"><span data-stu-id="abeba-167">**Ranges from -inf and 1.00, where 1.00 is perfect predictions and 0.00 indicates mean predictions**.</span></span> <span data-ttu-id="abeba-168">Ad esempio, se il valore equivale a 0,20, può essere interpretato come "la probabilità di una stima corretta è il 20% maggiore rispetto alla stima casuale"</span><span class="sxs-lookup"><span data-stu-id="abeba-168">For example, if the value equals 0.20, it can be interpreted as "the probability of a correct prediction is 20% better than random guessing"</span></span>|

<span data-ttu-id="abeba-169">La micro-accuratezza è generalmente più indicata per le esigenze aziendali di stime di ML.</span><span class="sxs-lookup"><span data-stu-id="abeba-169">Micro-accuracy is generally better aligned with the business needs of ML predictions.</span></span> <span data-ttu-id="abeba-170">Se si vuole selezionare una singola metrica per scegliere la qualità dell'attività di classificazione multiclasse, è in genere preferibile puntare alla micro-accuratezza.</span><span class="sxs-lookup"><span data-stu-id="abeba-170">If you want to select a single metric for choosing the quality of a multiclass classification task, it should usually be micro-accuracy.</span></span>

<span data-ttu-id="abeba-171">Ad esempio, per un'attività di classificazione dei ticket di supporto: (mapping dei ticket in arrivo con i team di supporto)</span><span class="sxs-lookup"><span data-stu-id="abeba-171">Example, for a support ticket classification task: (maps incoming tickets to support teams)</span></span>

- <span data-ttu-id="abeba-172">Micro-accuratezza: con quale frequenza un ticket in ingresso viene classificato per il team corretto?</span><span class="sxs-lookup"><span data-stu-id="abeba-172">Micro-accuracy -- how often does an incoming ticket get classified to the right team?</span></span>
- <span data-ttu-id="abeba-173">Macro-accuratezza: con quale frequenza un ticket in ingresso è corretto per un tipico team?</span><span class="sxs-lookup"><span data-stu-id="abeba-173">Macro-accuracy -- for an average team, how often is an incoming ticket correct for their team?</span></span>

<span data-ttu-id="abeba-174">In questo esempio, l'accuratezza macro pesa i piccoli team. un piccolo team che ottiene solo 10 ticket per anno viene conteggiato come un grande team con 10.000 ticket all'anno.</span><span class="sxs-lookup"><span data-stu-id="abeba-174">Macro-accuracy overweights small teams in this example; a small team that gets only 10 tickets per year counts as much as a large team with 10k tickets per year.</span></span> <span data-ttu-id="abeba-175">La micro-accuratezza in questo caso si adatta meglio all'esigenza aziendale di calcolare la quantità di tempo/denaro che è possibile risparmiare automatizzando il processo di instradamento dei ticket.</span><span class="sxs-lookup"><span data-stu-id="abeba-175">Micro-accuracy in this case correlates better with the business need of, "how much time/money can the company save by automating my ticket routing process".</span></span>

<span data-ttu-id="abeba-176">Per altre informazioni sulle metriche di classificazione multiclasse, vedere gli articoli seguenti:</span><span class="sxs-lookup"><span data-stu-id="abeba-176">For further details on multi-class classification metrics read the following articles:</span></span>

- [<span data-ttu-id="abeba-177">Micro e macro-media di precisione, richiamo e Punteggio F</span><span class="sxs-lookup"><span data-stu-id="abeba-177">Micro- and Macro-average of Precision, Recall, and F-Score</span></span>](https://rushdishams.blogspot.com/2011/08/micro-and-macro-average-of-precision.html)
- [<span data-ttu-id="abeba-178">Multiclass Classification with Imbalanced Dataset</span><span class="sxs-lookup"><span data-stu-id="abeba-178">Multiclass Classification with Imbalanced Dataset</span></span>](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a)

## <a name="evaluation-metrics-for-regression-and-recommendation"></a><span data-ttu-id="abeba-179">Metriche di valutazione per regressione e raccomandazione</span><span class="sxs-lookup"><span data-stu-id="abeba-179">Evaluation metrics for Regression and Recommendation</span></span>

<span data-ttu-id="abeba-180">Entrambe le attività di regressione e raccomandazione stimano un numero.</span><span class="sxs-lookup"><span data-stu-id="abeba-180">Both the regression and recommendation tasks predict a number.</span></span> <span data-ttu-id="abeba-181">Nel caso della regressione, il numero può essere qualsiasi proprietà di output influenzato dalle proprietà di input.</span><span class="sxs-lookup"><span data-stu-id="abeba-181">In the case of regression, the number can be any output property that is influenced by the input properties.</span></span> <span data-ttu-id="abeba-182">Per la raccomandazione, il numero è in genere un valore di classificazione (compreso tra 1 e 5) oppure una raccomandazione Yes/No, rappresentata rispettivamente da 1 e 0.</span><span class="sxs-lookup"><span data-stu-id="abeba-182">For recommendation, the number is usually a rating value (between 1 and 5 for example), or a yes/no recommendation (represented by 1 and 0 respectively).</span></span>

| <span data-ttu-id="abeba-183">Metrica</span><span class="sxs-lookup"><span data-stu-id="abeba-183">Metric</span></span>   |      <span data-ttu-id="abeba-184">Descrizione</span><span class="sxs-lookup"><span data-stu-id="abeba-184">Description</span></span>      |  <span data-ttu-id="abeba-185">Cercare</span><span class="sxs-lookup"><span data-stu-id="abeba-185">Look for</span></span> |
|----------|-----------------------|-----------|
| <span data-ttu-id="abeba-186">**R-Squared**</span><span class="sxs-lookup"><span data-stu-id="abeba-186">**R-Squared**</span></span> |  <span data-ttu-id="abeba-187">[R-squared (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination) o *coefficiente di determinazione* rappresenta la potenza predittiva del modello come valore compreso tra -inf e 1,00.</span><span class="sxs-lookup"><span data-stu-id="abeba-187">[R-squared (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination), or *Coefficient of determination* represents the predictive power of the model as a value between -inf and 1.00.</span></span> <span data-ttu-id="abeba-188">1,00 significa corrispondenza perfetta e la corrispondenza può essere arbitrariamente insufficiente, quindi i punteggi possono essere negativi.</span><span class="sxs-lookup"><span data-stu-id="abeba-188">1.00 means there is a perfect fit, and the fit can be arbitrarily poor so the scores can be negative.</span></span> <span data-ttu-id="abeba-189">Il punteggio 0,00 significa che il modello indovina il valore previsto per l'etichetta.</span><span class="sxs-lookup"><span data-stu-id="abeba-189">A score of 0.00 means the model is guessing the expected value for the label.</span></span> <span data-ttu-id="abeba-190">R2 misura il grado di prossimità dei valori dei dati di test effettivi ai valori stimati.</span><span class="sxs-lookup"><span data-stu-id="abeba-190">R2 measures how close the actual test data values are to the predicted values.</span></span> | <span data-ttu-id="abeba-191">**Quanto più vicino a 1,00, tanto migliore è la qualità**.</span><span class="sxs-lookup"><span data-stu-id="abeba-191">**The closer to 1.00, the better quality**.</span></span> <span data-ttu-id="abeba-192">Tuttavia, a volte i valori di R-squared bassi (ad esempio 0,50) possono essere perfettamente normali o sufficientemente validi per uno specifico scenario, mentre quelli alti non sono sempre validi e possono essere sospetti.</span><span class="sxs-lookup"><span data-stu-id="abeba-192">However, sometimes low R-squared values (such as 0.50) can be entirely normal or good enough for your scenario and high R-squared values are not always good and be suspicious.</span></span> |
| <span data-ttu-id="abeba-193">**Absolute-loss**</span><span class="sxs-lookup"><span data-stu-id="abeba-193">**Absolute-loss**</span></span> |  <span data-ttu-id="abeba-194">[Absolute-loss](https://en.wikipedia.org/wiki/Mean_absolute_error) o *errore assoluto medio* misura la prossimità delle stime ai risultati effettivi.</span><span class="sxs-lookup"><span data-stu-id="abeba-194">[Absolute-loss](https://en.wikipedia.org/wiki/Mean_absolute_error) or *Mean absolute error (MAE)* measures how close the predictions are to the actual outcomes.</span></span> <span data-ttu-id="abeba-195">Corrisponde alla media di tutti gli errori del modello, dove un errore del modello è la distanza tra il valore di etichetta stimato e quello corretto.</span><span class="sxs-lookup"><span data-stu-id="abeba-195">It is the average of all the model errors, where model error is the absolute distance between the predicted label value and the correct label value.</span></span> <span data-ttu-id="abeba-196">Questo errore di stima viene calcolato per ogni record del set di dati di test.</span><span class="sxs-lookup"><span data-stu-id="abeba-196">This prediction error is calculated for each record of the test data set.</span></span> <span data-ttu-id="abeba-197">Infine, viene calcolato il valore medio per tutti gli errori assoluti registrati.</span><span class="sxs-lookup"><span data-stu-id="abeba-197">Finally, the mean value is calculated for all recorded absolute errors.</span></span>| <span data-ttu-id="abeba-198">**Quanto più vicino a 0,00, tanto migliore è la qualità**.</span><span class="sxs-lookup"><span data-stu-id="abeba-198">**The closer to 0.00, the better quality.**</span></span> <span data-ttu-id="abeba-199">L'errore assoluto medio usa la stessa scala dei dati misurati (non viene normalizzato in un intervallo specifico).</span><span class="sxs-lookup"><span data-stu-id="abeba-199">The mean absolute error uses the same scale as the data being measured (is not normalized to specific range).</span></span> <span data-ttu-id="abeba-200">Le metriche Absolute-loss, Squared-loss e RMS-loss possono essere usate solo per eseguire confronti tra modelli per lo stesso set di dati o per un set di dati con una distribuzione simile dei valori di etichetta.</span><span class="sxs-lookup"><span data-stu-id="abeba-200">Absolute-loss, Squared-loss, and RMS-loss can only be used to make comparisons between models for the same dataset or dataset with a similar label value distribution.</span></span> |
| <span data-ttu-id="abeba-201">**Squared-loss**</span><span class="sxs-lookup"><span data-stu-id="abeba-201">**Squared-loss**</span></span> |  <span data-ttu-id="abeba-202">Il [quadratino di perdita](https://en.wikipedia.org/wiki/Mean_squared_error) o l' *errore quadratico medio (MSE)* , detto anche *media quadratica deviazione (MSD)* , indica il modo in cui la linea di regressione viene stabilita in un set di valori di dati di test prendendo le distanze dai punti alla retta di regressione (queste distanze sono gli errori e) e la quadratura.</span><span class="sxs-lookup"><span data-stu-id="abeba-202">[Squared-loss](https://en.wikipedia.org/wiki/Mean_squared_error) or *Mean Squared Error (MSE)*, also called *Mean Squared Deviation (MSD)*, tells you how close a regression line is to a set of test data values by taking the distances from the points to the regression line (these distances are the errors E) and squaring them.</span></span> <span data-ttu-id="abeba-203">La quadratura assegna più peso alle differenze maggiori.</span><span class="sxs-lookup"><span data-stu-id="abeba-203">The squaring gives more weight to larger differences.</span></span> | <span data-ttu-id="abeba-204">È sempre un valore non negativo e i **valori migliori sono quelli più vicini a 0,00**.</span><span class="sxs-lookup"><span data-stu-id="abeba-204">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="abeba-205">A seconda dei dati, può essere impossibile ottenere un valore molto piccolo per l'errore quadratico medio.</span><span class="sxs-lookup"><span data-stu-id="abeba-205">Depending on your data, it may be impossible to get a very small value for the mean squared error.</span></span>|
| <span data-ttu-id="abeba-206">**RMS-loss**</span><span class="sxs-lookup"><span data-stu-id="abeba-206">**RMS-loss**</span></span> |  <span data-ttu-id="abeba-207">[RMS-perdita](https://en.wikipedia.org/wiki/Root-mean-square_deviation) o *radice errore quadratico medio (valori RMSE)* (detta anche *deviazione radice media quadrata, RMSD*), misura la differenza tra i valori stimati da un modello e i valori osservati dall'ambiente in fase di modellazione.</span><span class="sxs-lookup"><span data-stu-id="abeba-207">[RMS-loss](https://en.wikipedia.org/wiki/Root-mean-square_deviation) or *Root Mean Squared Error (RMSE)* (also called *Root Mean Square Deviation, RMSD*), measures the difference between values predicted by a model and the values observed from the environment that is being modeled.</span></span> <span data-ttu-id="abeba-208">RMS-loss è la radice quadrata di Squared-loss e ha la stessa unità come etichetta, simile a absolute-loss ma assegnando più peso alle differenze maggiori.</span><span class="sxs-lookup"><span data-stu-id="abeba-208">RMS-loss is the square root of Squared-loss and has the same units as the label, similar to the absolute-loss though giving more weight to larger differences.</span></span> <span data-ttu-id="abeba-209">La radice dell'errore quadratico medio viene comunemente usata in climatologia, previsioni e analisi di regressione per verificare i risultati sperimentali.</span><span class="sxs-lookup"><span data-stu-id="abeba-209">Root mean square error is commonly used in climatology, forecasting, and regression analysis to verify experimental results.</span></span> | <span data-ttu-id="abeba-210">È sempre un valore non negativo e i **valori migliori sono quelli più vicini a 0,00**.</span><span class="sxs-lookup"><span data-stu-id="abeba-210">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="abeba-211">RMSD è una misura dell'accuratezza, per confrontare gli errori di previsione di diversi modelli per uno specifico set di dati e non tra set di dati, in quando è dipendente dalla scala.</span><span class="sxs-lookup"><span data-stu-id="abeba-211">RMSD is a measure of accuracy, to compare forecasting errors of different models for a particular dataset and not between datasets, as it is scale-dependent.</span></span>|

<span data-ttu-id="abeba-212">Per altre informazioni sulle metriche di regressione, vedere gli articoli seguenti:</span><span class="sxs-lookup"><span data-stu-id="abeba-212">For further details on regression metrics, read the following articles:</span></span>

- [<span data-ttu-id="abeba-213">Analisi di regressione: come si interpreta R-Squared e si valuta la bontà della soluzione?</span><span class="sxs-lookup"><span data-stu-id="abeba-213">Regression Analysis: How Do I Interpret R-squared and Assess the Goodness-of-Fit?</span></span>](https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)
- [<span data-ttu-id="abeba-214">How To Interpret R-squared in Regression Analysis</span><span class="sxs-lookup"><span data-stu-id="abeba-214">How To Interpret R-squared in Regression Analysis</span></span>](https://statisticsbyjim.com/regression/interpret-r-squared-regression)
- [<span data-ttu-id="abeba-215">R-Squared Definition</span><span class="sxs-lookup"><span data-stu-id="abeba-215">R-Squared Definition</span></span>](https://www.investopedia.com/terms/r/r-squared.asp)
- [<span data-ttu-id="abeba-216">Mean Squared Error Definition</span><span class="sxs-lookup"><span data-stu-id="abeba-216">Mean Squared Error Definition</span></span>](https://www.statisticshowto.datasciencecentral.com/mean-squared-error/)
- [<span data-ttu-id="abeba-217">What are Mean Squared Error and Root Mean Squared Error?</span><span class="sxs-lookup"><span data-stu-id="abeba-217">What are Mean Squared Error and Root Mean Squared Error?</span></span>](https://www.vernier.com/til/1014/)

## <a name="evaluation-metrics-for-clustering"></a><span data-ttu-id="abeba-218">Metriche di valutazione per il clustering</span><span class="sxs-lookup"><span data-stu-id="abeba-218">Evaluation metrics for Clustering</span></span>

| <span data-ttu-id="abeba-219">Metrica</span><span class="sxs-lookup"><span data-stu-id="abeba-219">Metric</span></span>   |      <span data-ttu-id="abeba-220">Descrizione</span><span class="sxs-lookup"><span data-stu-id="abeba-220">Description</span></span>      |  <span data-ttu-id="abeba-221">Cercare</span><span class="sxs-lookup"><span data-stu-id="abeba-221">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="abeba-222">**Distanza media**</span><span class="sxs-lookup"><span data-stu-id="abeba-222">**Average Distance**</span></span>|<span data-ttu-id="abeba-223">Media della distanza tra i punti dati e il centro del cluster assegnato.</span><span class="sxs-lookup"><span data-stu-id="abeba-223">Average of the distance between data points and the center of their assigned cluster.</span></span> <span data-ttu-id="abeba-224">La distanza media è una misura della prossimità dei punti dati al cluster centroidi.</span><span class="sxs-lookup"><span data-stu-id="abeba-224">The average distance is a measure of proximity of the data points to cluster centroids.</span></span> <span data-ttu-id="abeba-225">Si tratta di una misura della "stretta" del cluster.</span><span class="sxs-lookup"><span data-stu-id="abeba-225">It's a measure of how 'tight' the cluster is.</span></span>|<span data-ttu-id="abeba-226">I valori più vicini a **0** sono migliori.</span><span class="sxs-lookup"><span data-stu-id="abeba-226">Values closer to **0** are better.</span></span> <span data-ttu-id="abeba-227">Più vicino a zero è la distanza media, maggiore è il numero di cluster di dati.</span><span class="sxs-lookup"><span data-stu-id="abeba-227">The closer to zero the average distance is, the more clustered the data is.</span></span> <span data-ttu-id="abeba-228">Si noti tuttavia che questa metrica diminuirà se il numero di cluster viene aumentato e, nel caso estremo, in cui ogni punto dati distinto è il proprio cluster, sarà uguale a zero.</span><span class="sxs-lookup"><span data-stu-id="abeba-228">Note though, that this metric will decrease if the number of clusters is increased, and in the extreme case (where each distinct data point is its own cluster) it will be equal to zero.</span></span>
|<span data-ttu-id="abeba-229">**Indice Bouldin Davies**</span><span class="sxs-lookup"><span data-stu-id="abeba-229">**Davies Bouldin Index**</span></span>|<span data-ttu-id="abeba-230">Rapporto medio tra le distanze tra i cluster e le distanze tra i cluster.</span><span class="sxs-lookup"><span data-stu-id="abeba-230">The average ratio of within-cluster distances to between-cluster distances.</span></span> <span data-ttu-id="abeba-231">Più stretta è il cluster e, più a fondo, i cluster sono, minore è il valore.</span><span class="sxs-lookup"><span data-stu-id="abeba-231">The tighter the cluster, and the further apart the clusters are, the lower this value is.</span></span>|<span data-ttu-id="abeba-232">I valori più vicini a **0** sono migliori.</span><span class="sxs-lookup"><span data-stu-id="abeba-232">Values closer to **0** are better.</span></span> <span data-ttu-id="abeba-233">I cluster più lontani e meno dispersi comporteranno un punteggio migliore.</span><span class="sxs-lookup"><span data-stu-id="abeba-233">Clusters that are farther apart and less dispersed will result in a better score.</span></span>|
|<span data-ttu-id="abeba-234">**Informazioni comuni normalizzate**</span><span class="sxs-lookup"><span data-stu-id="abeba-234">**Normalized Mutual Information**</span></span>|<span data-ttu-id="abeba-235">Può essere usato quando i dati di training usati per eseguire il training del modello di clustering sono forniti anche con le etichette di verità (ovvero il clustering supervisionato).</span><span class="sxs-lookup"><span data-stu-id="abeba-235">Can be used when the training data used to train the clustering model also comes with ground truth labels (that is, supervised clustering).</span></span> <span data-ttu-id="abeba-236">La metrica delle informazioni comuni normalizzate misura se i punti dati simili vengono assegnati allo stesso cluster e i punti dati diversi vengono assegnati a cluster diversi.</span><span class="sxs-lookup"><span data-stu-id="abeba-236">The Normalized Mutual Information metric measures whether similar data points get assigned to the same cluster and disparate data points get assigned to different clusters.</span></span> <span data-ttu-id="abeba-237">Le informazioni comuni normalizzate sono un valore compreso tra 0 e 1</span><span class="sxs-lookup"><span data-stu-id="abeba-237">Normalized mutual information is a value between 0 and 1</span></span>|<span data-ttu-id="abeba-238">I valori più prossimi a **1** sono migliori</span><span class="sxs-lookup"><span data-stu-id="abeba-238">Values closer to **1** are better</span></span>|

## <a name="evaluation-metrics-for-ranking"></a><span data-ttu-id="abeba-239">Metriche di valutazione per la classificazione</span><span class="sxs-lookup"><span data-stu-id="abeba-239">Evaluation metrics for Ranking</span></span>

| <span data-ttu-id="abeba-240">Metrica</span><span class="sxs-lookup"><span data-stu-id="abeba-240">Metric</span></span>   |      <span data-ttu-id="abeba-241">Descrizione</span><span class="sxs-lookup"><span data-stu-id="abeba-241">Description</span></span>      |  <span data-ttu-id="abeba-242">Cercare</span><span class="sxs-lookup"><span data-stu-id="abeba-242">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="abeba-243">**Guadagni cumulativi scontati**</span><span class="sxs-lookup"><span data-stu-id="abeba-243">**Discounted Cumulative Gains**</span></span>|<span data-ttu-id="abeba-244">Il guadagno cumulativo scontato (DCG) è una misura della qualità di rango.</span><span class="sxs-lookup"><span data-stu-id="abeba-244">Discounted cumulative gain (DCG) is a measure of ranking quality.</span></span> <span data-ttu-id="abeba-245">Deriva da due presupposti.</span><span class="sxs-lookup"><span data-stu-id="abeba-245">It is derived from two assumptions.</span></span> <span data-ttu-id="abeba-246">Uno: gli elementi molto rilevanti sono più utili quando vengono visualizzati in ordine di rango superiore.</span><span class="sxs-lookup"><span data-stu-id="abeba-246">One: Highly relevant items are more useful when appearing higher in ranking order.</span></span> <span data-ttu-id="abeba-247">Due: l'utilità tiene traccia della pertinenza, maggiore è la pertinenza, più è utile un elemento.</span><span class="sxs-lookup"><span data-stu-id="abeba-247">Two: Usefulness tracks relevance that is, the higher the relevance, the more useful an item.</span></span> <span data-ttu-id="abeba-248">Il guadagno cumulativo scontato viene calcolato per una determinata posizione nell'ordine di rango.</span><span class="sxs-lookup"><span data-stu-id="abeba-248">Discounted cumulative gain is calculated for a particular position in the ranking order.</span></span> <span data-ttu-id="abeba-249">Viene sommata la classificazione della pertinenza divisa per il logaritmo dell'indice di rango fino alla posizione di interesse.</span><span class="sxs-lookup"><span data-stu-id="abeba-249">It sums the relevance grading divided by the logarithm of the ranking index up to the position of interest.</span></span> <span data-ttu-id="abeba-250">Viene calcolato tramite $ \ sum_ {i = 0} ^ {p} \frac {rel_i} {\ log_ {e} {i + 1}} $. le gradazioni di pertinenza vengono fornite a un algoritmo di training di rango come etichette di base.</span><span class="sxs-lookup"><span data-stu-id="abeba-250">It is calculated using $\sum_{i=0}^{p} \frac {rel_i} {\log_{e}{i+1}}$ Relevance gradings are provided to a ranking training algorithm as ground truth labels.</span></span> <span data-ttu-id="abeba-251">Viene fornito un valore DCG per ogni posizione nella tabella di classificazione, di conseguenza il nome ha scontato i **guadagni**cumulativi.</span><span class="sxs-lookup"><span data-stu-id="abeba-251">One DCG value is provided for each position in the ranking table, hence the name Discounted Cumulative **Gains**.</span></span> |<span data-ttu-id="abeba-252">**I valori più elevati sono migliori**</span><span class="sxs-lookup"><span data-stu-id="abeba-252">**Higher values are better**</span></span>|
|<span data-ttu-id="abeba-253">**Guadagni cumulativi scontati normalizzati**</span><span class="sxs-lookup"><span data-stu-id="abeba-253">**Normalized Discounted Cumulative Gains**</span></span>|<span data-ttu-id="abeba-254">La normalizzazione di DCG consente di confrontare la metrica per elenchi di rango di lunghezze diverse</span><span class="sxs-lookup"><span data-stu-id="abeba-254">Normalizing DCG allows the metric to be compared for ranking lists of different lengths</span></span>|<span data-ttu-id="abeba-255">**I valori più prossimi a 1 sono migliori**</span><span class="sxs-lookup"><span data-stu-id="abeba-255">**Values closer to 1 are better**</span></span>|

## <a name="evaluation-metrics-for-anomaly-detection"></a><span data-ttu-id="abeba-256">Metriche di valutazione per il rilevamento delle anomalie</span><span class="sxs-lookup"><span data-stu-id="abeba-256">Evaluation metrics for Anomaly Detection</span></span>

| <span data-ttu-id="abeba-257">Metrica</span><span class="sxs-lookup"><span data-stu-id="abeba-257">Metric</span></span>   |      <span data-ttu-id="abeba-258">Descrizione</span><span class="sxs-lookup"><span data-stu-id="abeba-258">Description</span></span>      |  <span data-ttu-id="abeba-259">Cercare</span><span class="sxs-lookup"><span data-stu-id="abeba-259">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="abeba-260">**Area sotto la curva ROC**</span><span class="sxs-lookup"><span data-stu-id="abeba-260">**Area Under ROC Curve**</span></span>|<span data-ttu-id="abeba-261">L'area sotto la curva operatore ricevitore misura il modo in cui il modello separa i punti dati anomali e usuali.</span><span class="sxs-lookup"><span data-stu-id="abeba-261">Area under the receiver operator curve measures how well the model separates anomalous and usual data points.</span></span>|<span data-ttu-id="abeba-262">**I valori più prossimi a 1 sono migliori**.</span><span class="sxs-lookup"><span data-stu-id="abeba-262">**Values closer to 1 are better**.</span></span> <span data-ttu-id="abeba-263">Solo i valori maggiori di 0,5 dimostrano l'efficacia del modello.</span><span class="sxs-lookup"><span data-stu-id="abeba-263">Only values greater than 0.5 demonstrate effectiveness of the model.</span></span> <span data-ttu-id="abeba-264">I valori 0,5 o seguenti indicano che il modello non è migliore dell'allocazione casuale degli input alle categorie anomale e consuete</span><span class="sxs-lookup"><span data-stu-id="abeba-264">Values of 0.5 or below indicate that the model is no better than randomly allocating the inputs to anomalous and usual categories</span></span>|
|<span data-ttu-id="abeba-265">**Frequenza di rilevamento con conteggio falso positivo**</span><span class="sxs-lookup"><span data-stu-id="abeba-265">**Detection Rate At False Positive Count**</span></span>|<span data-ttu-id="abeba-266">Il tasso di rilevamento a un conteggio falso positivo è il rapporto tra il numero di anomalie identificate correttamente e il numero totale di anomalie in un set di test, indicizzate da ogni falso positivo.</span><span class="sxs-lookup"><span data-stu-id="abeba-266">Detection rate at false positive count is the ratio of the number of correctly identified anomalies to the total number of anomalies in a test set, indexed by each false positive.</span></span> <span data-ttu-id="abeba-267">Ovvero, è presente un valore per la frequenza di rilevamento con numero di falsi positivi per ogni elemento falso positivo.</span><span class="sxs-lookup"><span data-stu-id="abeba-267">That is, there is a value for detection rate at false positive count for each false positive item.</span></span>|<span data-ttu-id="abeba-268">**I valori più prossimi a 1 sono migliori**.</span><span class="sxs-lookup"><span data-stu-id="abeba-268">**Values closer to 1 are better**.</span></span> <span data-ttu-id="abeba-269">Se non sono presenti falsi positivi, questo valore è 1</span><span class="sxs-lookup"><span data-stu-id="abeba-269">If there are no false positives, then this value is 1</span></span>|
